<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Wei Zhuo</title>
  
  <subtitle>始终在磕磕绊绊的摸索，至今依然是个无知的人</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-01-22T06:31:16.548Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Mario Z</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>《Enhanced Network Embeddings via Exploiting Edge Labels》阅读笔记</title>
    <link href="http://yoursite.com/2019/01/22/NE-Edge-Labels/"/>
    <id>http://yoursite.com/2019/01/22/NE-Edge-Labels/</id>
    <published>2019-01-22T03:02:29.000Z</published>
    <updated>2019-01-22T06:31:16.548Z</updated>
    
    <content type="html"><![CDATA[<p>论文地址: <a href="https://arxiv.org/abs/1809.05124?context=physics.soc-ph" target="_blank" rel="noopener">Enhanced Network Embeddings via Exploiting Edge Labels</a></p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>这是DeepWalk团队的一篇论文，目的是捕获网络中的边信息。传统的NE方法通常把节点简单关系当做（0,1）二值，然而边中所包含的丰富的语义信息。本文尝试做Network Embedding的同时保留网络结构和节点关系信息。举个例子来说，真实社交网络中，一个用户可能和他的同事，家人有关系，但是已有的NE方法不能同事捕获好友关系（有边连接），以及边的类型。</p><p>具体来说，本分的方法分为无监督部分和监督部分。其中无监督部分预测节点邻域， 监督部分预测边标签。所以本文模型是个<strong>半监督NE模型</strong>。</p><h2 id="Problem-Definition"><a href="#Problem-Definition" class="headerlink" title="Problem Definition"></a>Problem Definition</h2><p>假定Network Graph $G=(V,E)$是无向图。$L=(l_1,l_2,…,l_{|V|})$是边的类型集。一个含有边类型的Graph可以被重新定义为$G=(V,E_L,E_U,Y_L)$,其中$E_L$是由label的边集，$E_U$是没有label的边集，$E_L \cup E_U =E$。$Y_L$表示$E_L$中边的关系类型集合。论文中假定一条边可以有多重关系，所以对于边$E_i$的label集$Y_L(i) \in Y_L$, $Y_L(i)$可能包含很多类型 所以$Y_L(i) \subseteq L$。目的还是一样，学习一个映射函数$\Phi \to \mathbb{R}^{|V| \times d}$, 其中$d \ll |V|$。</p><h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><p>首先定义损失函数:  </p><script type="math/tex; mode=display">\mathcal{L}=(1-\lambda)\mathcal{L}_s+\lambda\mathcal{L}_r</script><p>其中$\mathcal{L}_s$表示预测节点邻域的损失。$\mathcal{L}_r$表示预测边label的损失。$\lambda$是两种损失的权重。</p><h3 id="Structural-Loss"><a href="#Structural-Loss" class="headerlink" title="Structural Loss"></a>Structural Loss</h3><p>第一部分是最小化无监督网络结构损失，对于一个给定的节点$v$, 要最大化这个节点和它邻域可能性。其中，节点的邻域不一定要一定和该节点有边相连。文章先给出了结构损失的目标函数：  </p><script type="math/tex; mode=display">\mathcal{L}_s=-\sum_{u \in C(v)} \log Pr(u|v)</script><p>这个函数其实就是给定$v$,最大化$v$的邻域的极大似然。其中$Pr(u|v)$是一个softmax函数：  </p><script type="math/tex; mode=display">Pr(u|v)=\frac{\exp(\Phi(u) \cdot \Phi'(v))}{\sum_{u' \in V} \exp(\Phi(u') \cdot \Phi'(v))}</script><p>这其实和DeepWalk一样，一个节点$v$有两个表示向量，$\Phi(v)$和$\Phi’(v)$分别表示该节点作为中心节点和上下文节点的表示。由于计算复杂度较高，所以采用负采样的策略。<br>剩下的问题就是如何构建节点$v$的邻域$C(v)$。一种直接的方式就是从邻接矩阵中选取他的邻居。然后由于现实网络的稀疏性，一个节点只有很少的邻居。为了缓解网络稀疏性的问题， 本文采取了类似于DeepWalk的randomwalk策略。 最终可以得到节点$v$的邻域：  </p><script type="math/tex; mode=display">C(v)=\{v_{i-w},...,v_{i-1}\} \cup \{v_{i+1},...,v_{i+w}\}</script><h3 id="Relational-Loss"><a href="#Relational-Loss" class="headerlink" title="Relational Loss"></a>Relational Loss</h3><p>由于label是为了预测边的，所以需要把每条边表示出来，所以对于边$e=(u,v) \in E$,可以用一下方法来表示这条边:  </p><script type="math/tex; mode=display">\Phi(e)=g(\Phi(u),\Phi(v))</script><p>其中，$g$是一个映射函数用来把两个节点的表示向量转化为他们之间边的表示向量，本文使用了简单的连接操作，即把两个向量直接拼接：  </p><script type="math/tex; mode=display">\Phi(e)=\Phi(u) \oplus \Phi(v)</script><p>这样我们就获得了edge embedding。直接将它输入前馈神经网络，前馈神经网络第$k$层的定义为:  </p><script type="math/tex; mode=display">h^{(k)}=f(W^{(k)}h^{(k-1)}+b^{(k)})</script><p>其中 $h^{(0)}=\Phi(e)$，$f$是除最后一层外采用relu激活函数，最后一层采用sigmoid函数激活,最后一层输出为$\hat{y_i}$。最后最小化二元交叉熵损失函数：</p><script type="math/tex; mode=display">\mathcal{L}_r=\sum^{|L|}_{i=1} H(y_i,\hat{y_i}) + (1-y_i) \cdot \log (1-\hat{y_i})</script><h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>这篇论文从原理到方法实现都非常简单，稍后我也将尝试复现这篇论文，边的标签信息是以前NE方法所没有考虑到的，但这篇论问的局限性是没有考虑边的方向以及权重，这是可以拓展的方向。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;论文地址: &lt;a href=&quot;https://arxiv.org/abs/1809.05124?context=physics.soc-ph&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Enhanced Network Embeddings via Ex
      
    
    </summary>
    
      <category term="Network Embedding" scheme="http://yoursite.com/categories/Network-Embedding/"/>
    
      <category term="paper" scheme="http://yoursite.com/categories/Network-Embedding/paper/"/>
    
    
      <category term="Hawkes process" scheme="http://yoursite.com/tags/Hawkes-process/"/>
    
      <category term="attention" scheme="http://yoursite.com/tags/attention/"/>
    
  </entry>
  
  <entry>
    <title>SDNE:《Structral Deep Network Embedding》阅读笔记</title>
    <link href="http://yoursite.com/2019/01/21/SDNE/"/>
    <id>http://yoursite.com/2019/01/21/SDNE/</id>
    <published>2019-01-21T07:34:36.000Z</published>
    <updated>2019-01-22T02:56:11.352Z</updated>
    
    <content type="html"><![CDATA[<p>论文地址：<a href="https://www.kdd.org/kdd2016/papers/files/rfp0191-wangAemb.pdf" target="_blank" rel="noopener">SDNE</a></p><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>这是一篇比较早的Network Embedding论文， 较早将深度模型应用到NE任务。 首先，本文提出了当前网络表示学习中遇到的三个问题：<br><strong>（1）. 高度非线性</strong><br><strong>（2）. 尽可能保持网络结构</strong><br><strong>（3）. 现实网络的高度稀疏性</strong><br>SDNE的主要目标就是保持网络结构的一阶相似性和二阶相似性。<br>一阶相似性就是网络中边相连的节点对之间具有的相似性。<br>二阶相似性就是在一个Graph中，拥有共同邻居但是不直接向相连的两个节点具有的相似性。</p><p>其中，一阶相似性主要反映了网络的局部特征。 二阶相似性反映了网络的全局特征。</p><h3 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h3><p>本文的模型主要如下图所示：</p><p><img src="/2019/01/21/SDNE/SDNE.png" alt="你想输入的替代文字"></p><p>这张图看上去有点复杂，实则原理非常简单。</p><p>模型分为无监督部分和有监督部分，无监督部分是一个<strong>深度自编码器</strong> 用来捕获二阶相似度（保留全局结构），监督部分是一个拉普拉斯特征映射捕获一阶相似度（局部结构）。呃呃呃，Emmmmm ,不知道是我理解有问题还是其他原因，文章里说的和我理解的不太一样 /(ㄒoㄒ)/~~。 然后介绍一下具体的模型结构：  </p><p>深度自编码器的编码部分：  </p><script type="math/tex; mode=display">y_i^{(k)}=\sigma{(W^{(k)}y_i^{(k-1)}+b^{(k)})}, k=2,...,K</script><p>假设第$k$层是 节点$v$的表示向量（仅考虑全局信息），那么从第$k$层开始解码，最终得到$\hat{x_i}$, 所以自编码器的误差就是输入节点$v$的邻接向量的重构误差。所以，二阶相似度损失函数定义为:  </p><script type="math/tex; mode=display">\mathcal{L}=\sum_{i=1}^n{||\hat{x_i}-x_i||^2_2}</script><p>值得注意的是，由于网络的稀疏性，邻接矩阵中的0元素远多于非0元素，使用邻接矩阵作为输入的话要处理很多0，这样就做了太多无用功了。为了解决这个问题，对损失函数做了改进如下：  </p><script type="math/tex; mode=display">\mathcal{L_{2nd}}=\sum_{i=1}^n||(\hat{x_i}-x_i)\odot{b_i}||^2_2=||\hat{X}-X\odot{B}||^2_F</script><p>其中$\odot$是哈马达乘积，表示对应元素相乘。$b_i=\{b_{i,j}\}^n_{j=1}$， 邻接矩阵中的0对应$b=1$, 非0元素的$b&gt;1$,这样的目的是对于有边连接的节点增加惩罚。可以理解为对有边连接的节点赋予更高权重。</p><p>以上我们获得了二阶相似度的损失函数。在介绍一阶相似度之前，我们先来看看<strong>拉普拉斯映射（Laplacian Eigenmap）</strong>  其实LE也是一种经典的NRL方法，主要目的也是降维。其目标函数如下所示:  </p><script type="math/tex; mode=display">\sum_{i,j} W_{ij}||y_i-y_j||^2</script><p>LE是通过构建相似关系图来重构局部特征结构,如果放在网络结构中来说,如果节点$v_i$和$v_j$很接近（有边），那么他们在embedding space中的距离也应该相应接近。$y_i$和$y_j$就表示他们在特征空间中的表示。因此，本文定义了保持一阶相似度的目标函数：  </p><script type="math/tex; mode=display">\mathcal{L_{1st}}=\sum_{i,j=1}^n{s_{i,j}||y_i^{(K)}-y_j^{(K)}||^2_2}=\sum_{i.j=1}^n{s_{i,j}||y_i-y_j||^2_2}</script><p>具体来说，$K$就是自编码器第$K$层的输出，即编码结果，需要保持一条边的两个节点在嵌入空间中的表示相对接近。</p><p>最终 结合一阶相似度和二阶相似度，本文给出了SDNE的目标函数：  </p><script type="math/tex; mode=display">\mathcal{L_{mix}}=\mathcal{L_{2nd}+\alpha{\mathcal{L_{1st}}}}+\nu{\mathcal{L_{reg}}} =||(\hat{X}-X)\odot{B}||^2_F+\alpha{\sum_{i.j=1}^n{s_{i,j}||y_i-y_j||^2_2}}+\nu{\mathcal{L_{reg}}}</script><p>其中，为了防止过拟合，添加了$\mathcal L2$-norm单元$\mathcal{L_{reg}}$来防止过拟合:  </p><script type="math/tex; mode=display">\mathcal{L_{reg}}=\frac{1}{2}\sum_{k=1}^k({||W^{(k)}||^2_F+||\hat{W}^{k}||_F^2})</script><h3 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h3><p>使用SGD来优化$\mathcal{L_{mix}}$。具体算法如下：<br><img src="/2019/01/21/SDNE/al.png" alt="你想输入的替代文字"></p><h3 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h3><p>不得不感叹这篇论文的实验是真的充分，分别在Link Prediction，Vertex Classification，Visualization上做了评价，并且都取得了高于Baselines的效果。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;论文地址：&lt;a href=&quot;https://www.kdd.org/kdd2016/papers/files/rfp0191-wangAemb.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDNE&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;Introduc
      
    
    </summary>
    
      <category term="Network Embedding" scheme="http://yoursite.com/categories/Network-Embedding/"/>
    
      <category term="paper" scheme="http://yoursite.com/categories/Network-Embedding/paper/"/>
    
    
      <category term="Deep Learning" scheme="http://yoursite.com/tags/Deep-Learning/"/>
    
      <category term="semi-supervised model" scheme="http://yoursite.com/tags/semi-supervised-model/"/>
    
  </entry>
  
  <entry>
    <title>图片边缘检测并且拟合直线</title>
    <link href="http://yoursite.com/2019/01/19/edge-detection-pj/"/>
    <id>http://yoursite.com/2019/01/19/edge-detection-pj/</id>
    <published>2019-01-18T16:00:00.000Z</published>
    <updated>2019-01-19T04:11:50.156Z</updated>
    
    <content type="html"><![CDATA[<p>前段时间做了一个简单的小项目，需求是测量图片中布的褶皱角度，第一次做CV的东西，决定用这个blog记录一下。 项目源码在:<a href="https://github.com/zhuo931077127/edge-detection" title="edge-detection" target="_blank" rel="noopener">edge-detection</a></p><p>先看看传统的边缘检测方法的效果:</p><p><img src="/2019/01/19/edge-detection-pj/tra.png" alt="你想输入的替代文字"></p><p>第一张图是原始图，由于本项目要求竟要求图片上半部分的褶皱角度，所以仅考虑上半部分的背景干扰，可以看出高斯，梯度，非极大抑制这三种方法都无法有效的排除干扰。<br>然后我们用canny算法试试。<br>步骤是先把图片转化为灰度图，然后用canny算子做边缘检测。<br>代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">gray = cv.cvtColor(image, cv.COLOR_RGB2GRAY)</span><br><span class="line">edges = cv.Canny(gray, 50, 310)  # apertureSize参数默认其实就是3  # 50 310</span><br><span class="line"># cv.imshow(&quot;edges&quot;, edges)</span><br><span class="line">edge = Image.fromarray(edges)</span><br><span class="line">edge.save(&quot;edge.jpeg&quot;)</span><br></pre></td></tr></table></figure></p><p>结果如下:  </p><p><img src="/2019/01/19/edge-detection-pj/edge.jpeg" alt="你想输入的替代文字"></p><p>霍夫线性变换拟合直线:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">lines = cv.HoughLines(edges, 1, np.pi / 180, 68)  # 68</span><br><span class="line">   # l1 = lines[:, 0, :]</span><br><span class="line">   # print(l1)</span><br><span class="line">   mink = float(&apos;inf&apos;)</span><br><span class="line">   maxk = -float(&apos;inf&apos;)</span><br><span class="line">   for line in lines:</span><br><span class="line">       rho, theta = line[0]  # line[0]存储的是点到直线的极径和极角，其中极角是弧度表示的。</span><br><span class="line">       a = np.cos(theta)  # theta是弧度</span><br><span class="line">       b = np.sin(theta)</span><br><span class="line">       x0 = a * rho  # 代表x = r * cos（theta）</span><br><span class="line">       y0 = b * rho  # 代表y = r * sin（theta）</span><br><span class="line">       x1 = int(x0 + 1000 * (-b))  # 计算直线起点横坐标</span><br><span class="line">       y1 = int(y0 + 1000 * a)  # 计算起始起点纵坐标</span><br><span class="line">       x2 = int(x0 - 1000 * (-b))  # 计算直线终点横坐标</span><br><span class="line">       y2 = int(y0 - 1000 * a)  # 计算直线终点纵坐标    注：这里的数值1000给出了画出的线段长度范围大小，数值越小，画出的线段越短，数值越大，画出的线段越长</span><br><span class="line">       print(&quot;x1: %s, y1:%s, x2:%s, y2:%s&quot; % (x1, y1, x2, y2))</span><br><span class="line">       k = (y2 - y1) / (x2 - x1)</span><br><span class="line">       if k &gt; maxk:</span><br><span class="line">           maxk = k</span><br><span class="line">           xmax1 = x1</span><br><span class="line">           ymax1 = y1</span><br><span class="line">           xmax2 = x2</span><br><span class="line">           ymax2 = y2</span><br><span class="line">           lineMax = line</span><br><span class="line">       if k &lt; mink:</span><br><span class="line">           mink = k</span><br><span class="line">           xmin1 = x1</span><br><span class="line">           ymin1 = y1</span><br><span class="line">           xmin2 = x2</span><br><span class="line">           ymin2 = y2</span><br><span class="line">           lineMin = line</span><br><span class="line">   cv.line(image, (xmax1, ymax1), (xmax2, ymax2), (255, 0, 0), 2)  # 点的坐标必须是元组，不能是列表。</span><br><span class="line">   cv.line(image, (xmin1, ymin1), (xmin2, ymin2), (255, 0, 0), 2)  # 点的坐标必须是元组，不能是列表。</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>值得注意的是，拟合直线过程中HoughLines会发现很多直线，因此，我选择了斜率最大和最小的两条直线做为最终的直线。画在图上的话就是酱紫的结果:</p><p><img src="/2019/01/19/edge-detection-pj/line.png" alt="你想输入的替代文字"></p><p>所以：总的过程可以概括如下:</p><p><img src="/2019/01/19/edge-detection-pj/final.jpeg" alt="你想输入的替代文字"></p><p>现在想这么弱智的项目居然还花了几天时间做，我是真滴蠢哦（T-T）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;前段时间做了一个简单的小项目，需求是测量图片中布的褶皱角度，第一次做CV的东西，决定用这个blog记录一下。 项目源码在:&lt;a href=&quot;https://github.com/zhuo931077127/edge-detection&quot; title=&quot;edge-detect
      
    
    </summary>
    
      <category term="project" scheme="http://yoursite.com/categories/project/"/>
    
      <category term="Computer Vision" scheme="http://yoursite.com/categories/project/Computer-Vision/"/>
    
    
      <category term="Edge detection" scheme="http://yoursite.com/tags/Edge-detection/"/>
    
  </entry>
  
  <entry>
    <title>HTNE:《Embedding Temporal Network via Neighborhood Formation》阅读笔记</title>
    <link href="http://yoursite.com/2019/01/17/HTNE/"/>
    <id>http://yoursite.com/2019/01/17/HTNE/</id>
    <published>2019-01-16T16:00:00.000Z</published>
    <updated>2019-01-19T13:37:37.503Z</updated>
    
    <content type="html"><![CDATA[<p>论文地址：<a href="https://dl.acm.org/citation.cfm?id=3220054" target="_blank" rel="noopener">HTNE</a></p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>本文出发点在于捕获动态网络中节点和边的变化来在embedding中保持网络结构，举个简单的例子来说，如Fig. 1所示，是一个共同作者网络图。数字标注的节点是author，方框内是co-authored paper. 可以看到图中每个节点每条边加入网络中的时间是不同的。根据图中的信息，可以分析出例如前期1和2，3合作较紧密，后期转为了6,7。 并且(b)中所示，同一条边可能多次出现，这就比传统的单条边拥有更多语义信息。</p><p><img src="/2019/01/17/HTNE/Fig1.png" alt="你想输入的替代文字"></p><p>另外，最近也有方法对动态网络的embedding做了研究，比如[29][30]的方法。但是他们的目的是将时间线分段为固定时间窗来对动态建模，但是这些方法依然没有考虑动态过程也就是网络随时序动态变化的信息。</p><p>因此，本文提出了基于霍克斯过程（Hawkes process）的时序网络表示学习方法，该方法是由序列事件驱动的（也就是序列的变化） 如Fig .1(b)所示 (b)图为节点1的邻域生成序列。霍克斯过程的思路是说历史上发生的事情对未来的概率密度函数有影响，只是随着时间流逝这种影响会逐渐减弱（Decay）。本文提出用霍克斯过程来捕获时间序列（也就是邻域生成序列）的激励效应。 尤其是历史事件对当前事件的影响。</p><p>通过把成对的向量映射到基本速率和历史影响，从而把低维向量被输入Hawkes过程。 </p><p>另外历史邻居当前邻居的影响，不同节点是不同的，所以本文使用attention model来学习历史邻居对当前邻居影响的量化表示。</p><p>值得注意的是，本文目标是优化邻域生成序列的极大似然估计即<strong>条件强度函数</strong>（conditional intensity function）来邻域生成序列的到达率，而不是条件概率函数</p><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><h3 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h3><p>本文通过跟踪节点邻域的形成来捕获网络的形成过程。<br><strong>Definition 1</strong> : 时序网络 $G=(V,E,A)$, $A$ 是事件集， 边$(x,y) \in E$ 被表示为按时间顺序的时间序列，例如， $\mathbf{a}_{x,y}=\{a_1\to{a_2}\to{…}\}\subset\mathcal{A}$, $a_i$ 表示时间$t_i$时刻的一个事件。  </p><p>因此，网络中节点的相邻邻居可以根据与邻居的交互事件的时序被组织为序列，表示邻域形成过程。</p><p><strong>Definition 2</strong> : 对于给定节点$x$,邻域表示为$N(x)=\{y_i|i=1,2…\}$.$x$的目标邻居到达事件可以表示为$\{x:(y_1,t_1)\to(y_2,t_2)\to…\to(y_n,t_n)\}$,即邻域形成序列。每个元组表示在时间戳$t_i$时，$x$与$y_i$建立边。</p><h3 id="Hawkes-Process"><a href="#Hawkes-Process" class="headerlink" title="Hawkes Process"></a>Hawkes Process</h3><p>点过程（Point Process）通过假设t时刻前的历史事件可以影响当前事件的发生，来对离散序列事件建模。<br>对于一个给定的节点$x \in V$, 在$x$的邻域生成序列中，到达目标邻居$y$的条件强度函数（或者可以说是$x$与$y$有边的可能性强度）可以表示为：  </p><script type="math/tex; mode=display">\tilde{\lambda}_{y|x}(t)=\mu_{x,y}+\sum_{t_h<t}{\alpha_{h,y}\kappa(t-t_{h})}</script><p>其中，$\mu_{x,y}$表示构建一条连接节点$x$和$y$的基本率(base rate)，$h$是t时刻前的历史目标节点，$\alpha_{h,y}$表示一个$t_h$时刻的历史目标节点$h$（该节点是$x$的邻居）对当前邻居$y$的影响强度。$\sum_{t_h&lt;t}$表示遍历t时刻前$x$的所有邻居。$\kappa(t-t_{h})$表示随时间的衰减，可以表示成指数函数：  </p><script type="math/tex; mode=display">\kappa(t-t_h)=\exp(-\delta_s(t-t_h))</script><p>其中，减少率 $\delta$是一个源依赖参数，对于每一个源节点（每个序列的根），历史邻居对当前邻居形成的影响强度是不同的。具体来说，如果$\kappa$越大，说明$t_h$时刻的邻居对当前邻居的影响越大，即 $-\delta_s(t-t_h)$越大, $\delta_s(t-t_h)$越小，因为$t$是当前时刻的邻居，所以当$t_h$越接近当前邻居时刻时，$\kappa$越大，这就说明了里当前时刻之前越近的邻居，对当前时刻邻居的影响越大。<br>综上所述，$\kappa$的具体意义是随时间衰减的影响，其中$\delta_s$参数表示对于不同的源节点，影响是不同的。</p><p>如果$\tilde{\lambda}_{y|x}(t)$ 越大，说明x和y有边的可能性也越大。</p><p>直观的来看，基本率（base rate）$\mu_{x,y}$揭示了节点x和节点y之间的连接可能性。为了简洁，本文使用了<strong>负平方欧式距离（negative squared Euclidean）</strong>来反映表示向量间的相似度: $\mu_{x,y}=f(\mathbf{e}_x,\mathbf{e}_y)=-||\mathbf{e}_x-\mathbf{e}_y||^2$。同样的，在计算历史邻居$h$对当前邻居$y$的影响时，也采用这个方法，即： $\alpha_{h,y}=f(\mathbf{e}_h,\mathbf{e}_y)=-||\mathbf{e}_h-\mathbf{e}_y||^2$。<br>因为条件强度函数必须为正，所以使用如下公式: $\lambda_{y|x}(t)=\exp(\tilde\lambda_{y|x}(t))$。$exp()$对原函数进行了归一化，所以问题就转化为了given $x$, maximize likelihood: $p(y|x)$. 这就与传统的NE方法差不多了。。。</p><h3 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h3><p>根据论文中（3）式，可以看出，$\sum_{t_h&lt;t}{\alpha_{h,y}\kappa(t-t_{h})}$这一部分主要描述了历史邻居对当前邻居的影响，但是完全忽略了源节点$x$，因为源节点$x$的变化也会影响到历史邻居对当前邻居的亲近程度(affinity)。因此，本文引入了<strong>attention model</strong>。as follows：  </p><script type="math/tex; mode=display">w_{h,x} = \frac{\exp(-||\mathbf{e}_x-\mathbf{e}_h||^2)}{\sum_{h'}{\exp(-||\mathbf{e}_x-\mathbf{e}_{h'}||^2)}}</script><p>这是一个softmax函数 来根据源节点$x$的不同为它的邻居赋予不同权重。</p><p>最后， 历史邻居与当前邻居的连接紧密程度可以表示为:</p><script type="math/tex; mode=display">\alpha_{h,y}=w_{h,x}f(\mathbf{e}_h,\mathbf{e}_y)</script><h3 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h3><p>目标函数即为给定节点$x$以及基于邻域形成序列的霍克斯过程, 生成节点$y$的条件概率。 公式如下：</p><script type="math/tex; mode=display">p(y|x, \mathcal{H}_x(t)) = \frac{\lambda_{y|x}(t)}{\sum_{y'}{\lambda_{y'|x}(t)}}</script><p>目标函数即为所有节点对的极大似然：</p><script type="math/tex; mode=display">\log \mathcal{L}=\sum_{x\in{\mathcal{V}}}{\sum_{y\in{\mathcal{H}_x}}}{\log{p(y|x,\mathcal{H}(t))}}</script><p>最后，由于softmax过程是calculating expensive，所以采用负采样优化损失函数。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;论文地址：&lt;a href=&quot;https://dl.acm.org/citation.cfm?id=3220054&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;HTNE&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Int
      
    
    </summary>
    
      <category term="Network Embedding" scheme="http://yoursite.com/categories/Network-Embedding/"/>
    
      <category term="paper" scheme="http://yoursite.com/categories/Network-Embedding/paper/"/>
    
    
      <category term="Hawkes process" scheme="http://yoursite.com/tags/Hawkes-process/"/>
    
      <category term="attention" scheme="http://yoursite.com/tags/attention/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://yoursite.com/2019/01/16/hello-world/"/>
    <id>http://yoursite.com/2019/01/16/hello-world/</id>
    <published>2019-01-15T16:00:00.000Z</published>
    <updated>2019-01-17T06:48:31.411Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
      <category term="test" scheme="http://yoursite.com/categories/test/"/>
    
    
  </entry>
  
</feed>
