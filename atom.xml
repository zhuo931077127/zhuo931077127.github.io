<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Wei Zhuo</title>
  
  <subtitle>始终在磕磕绊绊的摸索，至今依然是个无知的人</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-04-02T08:33:22.390Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Mario Z</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Opencv轮廓提取并计算图片中某一封闭区域的面积</title>
    <link href="http://yoursite.com/2019/04/02/Pic-closed-edge/"/>
    <id>http://yoursite.com/2019/04/02/Pic-closed-edge/</id>
    <published>2019-04-02T07:43:44.000Z</published>
    <updated>2019-04-02T08:33:22.390Z</updated>
    
    <content type="html"><![CDATA[<p>最近遇到一个问题，之前在<a href="https://zhuo931077127.github.io/2019/01/19/edge-detection-pj/" target="_blank" rel="noopener">这篇文章</a>中提到过一个边缘检测并且拟合直线的方法。但是如果需要计算区域内的面积，比如说要计算下图中类似三角形区域内的面积<br><img src="/2019/04/02/Pic-closed-edge/cut.jpeg" alt="你想输入的替代文字"><br>之前的做法是用Canny算子提取边缘，再用HoughLines拟合直线，然后求出交点坐标并计算三角形面积，其中，边缘提取后的图像如下图所示：<br><img src="/2019/04/02/Pic-closed-edge/edge.jpeg" alt="你想输入的替代文字"><br>我们可以很明显的看出这不是一个标准的三角形，所以如果想要更精确的获得三角形，就需要对图片进行轮廓提取，然后计算轮廓内区域的面积。这里给出代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># Input image</span><br><span class="line">img = cv2.imread(&apos;cut.jpeg&apos;, cv2.IMREAD_GRAYSCALE)</span><br><span class="line"></span><br><span class="line"># Needed due to JPG artifacts</span><br><span class="line">_, temp = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY)</span><br><span class="line"></span><br><span class="line"># Dilate to better detect contours</span><br><span class="line">temp = cv2.dilate(temp, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)))</span><br><span class="line"></span><br><span class="line"># Find largest contour</span><br><span class="line">_, cnts, _ = cv2.findContours(temp, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)</span><br><span class="line">largestCnt = []</span><br><span class="line">for cnt in cnts:</span><br><span class="line">    if len(cnt) &gt; len(largestCnt):</span><br><span class="line">        largestCnt = cnt</span><br><span class="line"></span><br><span class="line"># Determine center of area of largest contour</span><br><span class="line">M = cv2.moments(largestCnt)</span><br><span class="line">x = int(M[&quot;m10&quot;] / M[&quot;m00&quot;])</span><br><span class="line">y = int(M[&quot;m01&quot;] / M[&quot;m00&quot;])</span><br><span class="line"></span><br><span class="line"># Initiale mask for flood filling</span><br><span class="line">width, height = temp.shape</span><br><span class="line">mask = img2 = np.ones((width + 2, height + 2), np.uint8) * 255</span><br><span class="line">mask[1:width, 1:height] = 0</span><br><span class="line"></span><br><span class="line"># Generate intermediate image, draw largest contour, flood filled</span><br><span class="line">temp = np.zeros(temp.shape, np.uint8)</span><br><span class="line">temp = cv2.drawContours(temp, largestCnt, -1, 255, cv2.FILLED)</span><br><span class="line">_, temp, mask, _ = cv2.floodFill(temp, mask, (x, y), 255)</span><br><span class="line">temp = cv2.morphologyEx(temp, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)))</span><br><span class="line"></span><br><span class="line"># Count pixels in desired region</span><br><span class="line">area = cv2.countNonZero(temp)</span><br><span class="line"></span><br><span class="line"># Put result on original image</span><br><span class="line">img = cv2.putText(img, str(area), (x, y), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, 255)</span><br><span class="line"></span><br><span class="line">cv2.imshow(&apos;Input&apos;, img)</span><br><span class="line">cv2.imshow(&apos;Temp image&apos;, temp)</span><br><span class="line"></span><br><span class="line">cv2.waitKey(0)</span><br><span class="line"></span><br></pre></td></tr></table></figure></p><p>最后我们可以得到一个比较准确的轮廓：<br><img src="/2019/04/02/Pic-closed-edge/img_trk.jpg" alt="你想输入的替代文字"><br>面积如图中所示：<br><img src="/2019/04/02/Pic-closed-edge/img_tr.jpg" alt="你想输入的替代文字">  </p><p>参考：<br><a href="https://stackoverflow.com/questions/55467031/how-to-get-the-area-of-the-contours" target="_blank" rel="noopener">https://stackoverflow.com/questions/55467031/how-to-get-the-area-of-the-contours</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近遇到一个问题，之前在&lt;a href=&quot;https://zhuo931077127.github.io/2019/01/19/edge-detection-pj/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;这篇文章&lt;/a&gt;中提到过一个边缘检测并且拟合
      
    
    </summary>
    
      <category term="project" scheme="http://yoursite.com/categories/project/"/>
    
      <category term="Computer Vision" scheme="http://yoursite.com/categories/project/Computer-Vision/"/>
    
    
      <category term="Contours" scheme="http://yoursite.com/tags/Contours/"/>
    
  </entry>
  
  <entry>
    <title>社交网络影响最大化（Influence Maximization）中的IC，LT模型</title>
    <link href="http://yoursite.com/2019/03/20/IC-LT/"/>
    <id>http://yoursite.com/2019/03/20/IC-LT/</id>
    <published>2019-03-20T13:34:08.000Z</published>
    <updated>2019-03-20T14:58:39.229Z</updated>
    
    <content type="html"><![CDATA[<h1 id="The-Independent-Cascade-Model-IC-Model"><a href="#The-Independent-Cascade-Model-IC-Model" class="headerlink" title="The Independent Cascade Model (IC Model)"></a>The Independent Cascade Model (IC Model)</h1><p>IC模型，即独立级联模型。 $v$表示图$G=（V,E)$中的一个节点（用户），$v$可以被它的传入邻居（incoming neighbor）以一个影响概率$p_{u,v}$的情况下独立激活。<br>在时间步为0的时候，给定一个种子集（seed set）$S$,即$k$个已经是激活着的节点。 在时间步$t$时，每一个激活状态的节点$u$将会以一定的概率$p_{u,v}$来激活每一个和它连接的未激活节点$v$。时间步$t$之后，如果$v$依然是未激活状态，那么$v$将无法再次被$v$激活。结束一次上述过程后，$u$保持激活状态并且失去激活其他节点的能力。当网络$G$中没有其他节点可以被激活时，扩散过程结束。<br>值得注意的是，当$S$是原始的激活节点集，那么上述随机激活过程完成后，所得到的影响分布（Influence Spread）是所期望的激活节点数。</p><h1 id="The-Linear-Threshold-Model-LT-Model"><a href="#The-Linear-Threshold-Model-LT-Model" class="headerlink" title="The Linear Threshold Model (LT Model)"></a>The Linear Threshold Model (LT Model)</h1><p>LT模型，即线性阈值模型。基本思想是，如果一个未被激活的节点有足够的传入邻居是激活状态的，那么该节点可以被激活。<br>形式上， 在图$G$中每条边$e=(u,v) \in E$有一个权重$b_{u,v}$。 我们定义$\mathcal{N}_I (v)$表示节点$v$的传入节点， 满足$\sum_{u \in \mathcal{N}_I (v)} b_{u,v} \leq 1$, 即所有$v$的传入节点与$v$组成的边的权重只和小于1。 另外，每个节点$v$具有一个阈值$\theta_v$。 LT模型首先为每个节点$v$的阈值$\theta_v$在$[0,1]$上均匀随机采样。在时间步0时，设置$S$中的节点状态为激活，其他节点为未激活，然后迭代的更新每个节点的状态。 在时间步$t$时，所有$t-1$时刻是激活状态的节点依旧保持激活状态，与此同时，其他未激活的节点$v$, 如果任意一个节点$v$的激活传入邻居总权重的值至少为$\theta_v$,那么将$v$激活。 当没有节点将要被激活时，传播结束。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;The-Independent-Cascade-Model-IC-Model&quot;&gt;&lt;a href=&quot;#The-Independent-Cascade-Model-IC-Model&quot; class=&quot;headerlink&quot; title=&quot;The Independent 
      
    
    </summary>
    
      <category term="Social Network Analysis" scheme="http://yoursite.com/categories/Social-Network-Analysis/"/>
    
      <category term="Influence Maximization" scheme="http://yoursite.com/categories/Social-Network-Analysis/Influence-Maximization/"/>
    
    
      <category term="IM" scheme="http://yoursite.com/tags/IM/"/>
    
  </entry>
  
  <entry>
    <title>《BiNE:Bipartite Network Embedding》阅读笔记</title>
    <link href="http://yoursite.com/2019/03/13/BiNE/"/>
    <id>http://yoursite.com/2019/03/13/BiNE/</id>
    <published>2019-03-13T14:01:15.000Z</published>
    <updated>2019-03-14T06:21:25.863Z</updated>
    
    <content type="html"><![CDATA[<p>论文地址：<a href="https://www.comp.nus.edu.sg/~xiangnan/papers/sigir18-bipartiteNE.pdf" target="_blank" rel="noopener">BiNE</a></p><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p><strong>Bipartite Network(二分网络)</strong>:如下图所示：<br><img src="/2019/03/13/BiNE/stru.png" alt="你想输入的替代文字"><br>二分网络将节点分为两种类型，其中 边存在于两种类型之间，例如users-items组成的推荐网络，相同类型节点间不会产生边。传统的Network Embedding将bipartite network视为同质网络（homogeneous network）， 也就是仅考虑直接联系的边。这样就存在一个问题，即在同一个类型中的节点，虽然没有直接的连接，但是也可能有间接的关系。比如两个用户同时连接到同一个商品，则这两个用户可能有有相同的购买偏好。</p><p>另一个问题，<br><img src="/2019/03/13/BiNE/r1.png" alt="你想输入的替代文字"> <img src="/2019/03/13/BiNE/r2.png" alt="你想输入的替代文字"><br>如上两图所示， 图一可以看出，节点被访问的词数和考虑到的节点数呈现斜率为-1.582的幂律分布，但是基于随机游走的生成器相对于真实分布有所偏差， 文中分析原因在于基于随机游走的模型DeepWalk为每个节点生成相同长度的节点序列（walk_length）并且每个节点所需要的随机游走次数（walk per vertex）也是完全相同的，这样无法反应网络的特征以及异构性。<br>另外，对于Heterogeneous Network Embedding方法metapath2vec++, 此方法是次优的因为它将直接连接的节点与间接有关系的节点视为等价。</p><p>针对以上问题，BiNE为直接连接和间接关系分别设计了专用的目标函数，并且联合优化。 并且，所及游走的长度由该节点的重要程度决定，节点的重要程度通过<a href="http://www.cs.cornell.edu/home/kleinber/auth.pdf" target="_blank" rel="noopener">HITS</a>来衡量。</p><h1 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h1><p>如figure中的二分网络， 可以这样定义：$G=(U,V,E)$,和一个$|U| \times |V|$的$W=[w_{ij}]$为权重矩阵。输出d维embedding向量$U=[\overrightarrow{u_i}]$, $V=[\overrightarrow{v_i}]$，结构如下图所示：<br><img src="/2019/03/13/BiNE/3.png" alt="你想输入的替代文字">（取自作者的讲解ppt）  </p><h2 id="Explicit-Relations"><a href="#Explicit-Relations" class="headerlink" title="Explicit Relations"></a>Explicit Relations</h2><p>同LINE一样， 基于直接连接的目标函数表示为：  </p><script type="math/tex; mode=display">minimize \quad O_1=-\sum_{e_{ij} \in E}w_{ij}\log \hat{P}(i,j)</script><h2 id="Implicit-Relations"><a href="#Implicit-Relations" class="headerlink" title="Implicit Relations"></a>Implicit Relations</h2><h3 id="构造随机游走序列"><a href="#构造随机游走序列" class="headerlink" title="构造随机游走序列"></a>构造随机游走序列</h3><p>这是本文的创新点，分别为$U$和$U$构建语料库，即随机游走序列$D^U$和$D^V$。 首先给出两个同type节点相似度的定义：  </p><script type="math/tex; mode=display">w^U_{ij}=\sum_{k \in V}w_{ik}w_{jk}</script><script type="math/tex; mode=display">w^V_{ij}=\sum_{k \in U}w_{ki}w_{kj}</script><p>其中$i$和$j$是为$U$或$V$中的同类节点，也就是说两个同类节点如果有共同目标顶点，那么他们的2介相似度不为0。 则$U$中的二阶权重矩阵$|U|\times|U|$维矩阵$W^U=[w^U_{ij}]$。$V$中同理。<br><img src="/2019/03/13/BiNE/Al1.png" alt="你想输入的替代文字"><br>其中$l=max(H(v_i)\times maxT,minT)$, $H(v_i)$为节点$v_i$的中心性，中心性由HITS衡量。$l$为节点$v$的random walk次数（the number of random walks）,有这个节点的重要程度（centrality/importance）决定。  </p><script type="math/tex; mode=display">D_{v_i}=BiasedRandomWalk(W^R,v_i,p)</script><p>表示其中一次随机游走的节点集合$p$表示停止概率。</p><p>通过上面的推导，可以对分别对$U$,$V$中的节点构早随机游走序列，以$U$为例，若$S\in D^U$表示 那么$S$就是$U$中的一个随机游走序列。</p><h3 id="对间接关系建模"><a href="#对间接关系建模" class="headerlink" title="对间接关系建模"></a>对间接关系建模</h3><p>如下图所示（图片取自作者的ppt），$S$为$D^U$中的一个随机游走序列， 其中$u_i$是这个序列的中心点，$C_s(u_i)$是$u_i$的上下文节点。<br><img src="/2019/03/13/BiNE/dd.png" alt="你想输入的替代文字"><br>对于$U$中的随机游走序列结合$D^U$，我们要做的就是最大化给定$u_i$,生成$u_c \in C_s(u_i)$的条件概率。所以目标函数如下：</p><script type="math/tex; mode=display">maximize \quad O_2 = \prod_{u_i \in S \land S \in D^U} \prod_{u_c \in C_s(u_i)}P(u_c|u_i)</script><p>对于$D^V$同理。其中,$p(u_c|u_i) = \frac{\exp(\overrightarrow{u}_i^T \overrightarrow{\theta}_c)}{\sum^{|U|}_{k=1} \exp(\overrightarrow{u}_i^T \overrightarrow{\theta}_k))}$。</p><h3 id="Negative-Sampling"><a href="#Negative-Sampling" class="headerlink" title="Negative Sampling"></a>Negative Sampling</h3><p>本文的负采样方法是基于局部敏感哈希（LSH）来对与中心节点不相似的节点进行采样。<br>该方法的strategy是，给定一个中心节点，随机选取一个bucket（序列）并且这个序列不包含给定的中心节点，以此来获得和给定节点尽量不相似的负采样节点。<br>$N^{ns}_S (u_i)$ 表示$ns$个负采样节点，对于中心节点$u_i$, 那么上文提到的条件概率$p(u_c|u_i)$可以被定义为下式：  </p><script type="math/tex; mode=display">p(u_c,N^{ns}_S (u_i)|u_i) = \prod_{z \in \{u_c\} \cup N^{ns}_S (u_i)} P(z|u_i)</script><p>其中条件概率$P(z|u_i)$定义为：<br><img src="/2019/03/13/BiNE/4.png" alt="你想输入的替代文字"><br>其中$\sigma$表示sigmoid函数，这样就减少了上文softmax函数造成的计算量过大的问题。</p><h2 id="联合优化"><a href="#联合优化" class="headerlink" title="联合优化"></a>联合优化</h2><p>通过随机梯度上升对3部分损失函数进行加权优化：  </p><script type="math/tex; mode=display">maximize \quad L = \alpha \log O_2+\beta \log O_3 - \gamma O_1</script><p>最终BiNE的整体算法流程如下：<br><img src="/2019/03/13/BiNE/Al2.png" alt="你想输入的替代文字">  </p><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>这篇文章提出的分布式训练以及负采样策略还是很值得学习的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;论文地址：&lt;a href=&quot;https://www.comp.nus.edu.sg/~xiangnan/papers/sigir18-bipartiteNE.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;BiNE&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;I
      
    
    </summary>
    
      <category term="Network Embedding" scheme="http://yoursite.com/categories/Network-Embedding/"/>
    
      <category term="paper" scheme="http://yoursite.com/categories/Network-Embedding/paper/"/>
    
    
      <category term="Bipartite Network" scheme="http://yoursite.com/tags/Bipartite-Network/"/>
    
      <category term="SGA" scheme="http://yoursite.com/tags/SGA/"/>
    
  </entry>
  
  <entry>
    <title>深度学习中的优化算法总结</title>
    <link href="http://yoursite.com/2019/02/28/Optimizer/"/>
    <id>http://yoursite.com/2019/02/28/Optimizer/</id>
    <published>2019-02-28T03:48:28.000Z</published>
    <updated>2019-03-18T06:02:49.100Z</updated>
    
    <content type="html"><![CDATA[<p>最近想好好学一学Deep Learning中的优化算法（不能一直Adam了），看了一些文献，用这篇文章做个总结笔记。</p><h2 id="Gradient-Desent-梯度下降"><a href="#Gradient-Desent-梯度下降" class="headerlink" title="Gradient Desent(梯度下降)"></a>Gradient Desent(梯度下降)</h2><p>目标函数$f(x)$，其中$x$为模型的待优化参数，对于每个epoch $t$, $\eta_t$表示第$t$个epoch的步长。$x_t$第$t$个epoch时的参数。<br>(1).梯度下降的原理：目标函数（损失函数）$f(x)$关于参数$x$的梯度是损失函数上升最快的方向。所以只要让$x$沿梯度的反方向走，就可以缩小目标函数。<br>(2).目标函数关于参数$x$在epoch $t$时的梯度：  </p><script type="math/tex; mode=display">g_t = \nabla_x f(x_t)</script><p>(3).我们要最小化$f(x)$, 所以参数$x$需要往梯度的反方向移动：  </p><script type="math/tex; mode=display">x_{t+1} = x_t-\eta_t g_t</script><p>其中$x_{t+1}$为$t+1$时刻的参数值。</p><h2 id="Stochastic-Gradient-Desent-随机梯度下降"><a href="#Stochastic-Gradient-Desent-随机梯度下降" class="headerlink" title="Stochastic Gradient Desent(随机梯度下降)"></a>Stochastic Gradient Desent(随机梯度下降)</h2><p>梯度下降存在的问题有鞍点问题以及无法找到全局最优解的问题。所以引入SGD。<br>首先给出无偏估计的定义，稍后会用到：<br><a href="https://www.cnblogs.com/notwice/p/8538539.html" target="_blank" rel="noopener">无偏估计</a>：估计量的均值等于真实值，即具体每一次估计值可能大于真实值，也可能小于真实值，而不能总是大于或小于真实值（这就产生了系统误差）。  </p><p>深度学习中，目标函数通常是训练集中各个样本损失的平均，假设一个batch的大小为$n$，那么训练这个batch的损失就是$f_{batch}(x) = \frac{\displaystyle\sum_{i=1}^{n} f_i(x)}{n}$ , 所以目标函数对$x$的梯度就是：  </p><script type="math/tex; mode=display">\nabla f_{batch}(x) = \frac{1}{n} \displaystyle\sum_{i=1}^n \nabla f_i(x)</script><p>如果使用GD来优化：  </p><script type="math/tex; mode=display">x_{t+1} = x_{t}- \eta_t \frac{1}{n} \displaystyle\sum_{i=1}^n \nabla f_i(x) \\ = x_t-\eta_t \nabla f_{batch}(x)</script><p>上式可以看出，当训练样本非常大时，n也将边的非常大，那么梯度计算的计算开销就比较大。</p><p>随机梯度下降（SGD）的思想是： 以一个batch为例，这个batch中有n个样本，每个样本$i \in \{1, \cdots,n\}$, 每次从中随机选取一个样本来更新参数$x$。  </p><script type="math/tex; mode=display">x_{t+1} = x_{t}-\eta_t \nabla f_i(x)</script><p>这样就更新了一个batch的参数。 对比上面两个式子可以看出SGD降低了计算复杂度。上面两个式子是等价的，因为随机梯度$\nabla f_i(x)$是对梯度$\nabla f_{batch}(x)$的无偏估计，因为：  </p><script type="math/tex; mode=display">E_i \nabla f_i(\boldsymbol{x}) = \frac{1}{n} \sum_{i = 1}^n \nabla f_i(\boldsymbol{x}) = \nabla f_{batch}(\boldsymbol{x})</script><p>符合无偏估计的定义。</p><h2 id="Momentum-动量法"><a href="#Momentum-动量法" class="headerlink" title="Momentum(动量法)"></a>Momentum(动量法)</h2><h3 id="Exponentially-weighted-moving-averages-EMA"><a href="#Exponentially-weighted-moving-averages-EMA" class="headerlink" title="Exponentially weighted moving averages(EMA)"></a>Exponentially weighted moving averages(EMA)</h3><p>EMA,指数加权移动平均数。</p><p>在GD中,如果学习率过大，会导致目标函数发散，而无法逼近最小值，如下图所示：<br><img src="/2019/02/28/Optimizer/EMA_1.png" alt="你想输入的替代文字"><br>如果学习率很低，那么会缓慢接近最优点，如下图红色轨迹：<br><img src="/2019/02/28/Optimizer/EMA_2.png" alt="你想输入的替代文字"><br>我们希望在学习率较小的时候可以更快逼近最优点，在学习率大的时候自变量可以不发散，即在正确的方向上加速下降并且抑制震荡，也就是达到如下的效果：<br><img src="/2019/02/28/Optimizer/EMA_3.svg" alt="你想输入的替代文字">   </p><p>因此引入EMA。给定参数$0 \leq \gamma &lt; 1$,当前时间步$t$的变量$y_t$是上一时间步$t-1$的变量$y_{t-1}$和当前时间步另一变量$x_t$的线性组合。  </p><script type="math/tex; mode=display">y_t = \gamma y_{t-1} + (1-\gamma) x_t</script><p>展开上式:  </p><script type="math/tex; mode=display">\begin{split}\begin{aligned}y_t  &= (1-\gamma) x_t + \gamma y_{t-1}\\         &= (1-\gamma)x_t + (1-\gamma) \cdot \gamma x_{t-1} + \gamma^2y_{t-2}\\         &= (1-\gamma)x_t + (1-\gamma) \cdot \gamma x_{t-1} + (1-\gamma) \cdot \gamma^2x_{t-2} + \gamma^3y_{t-3}\\         &\ldots\end{aligned}\end{split}</script><p>上式可以看出当前时刻变量是对过去时刻变量做指数加权，离当前时刻越近，加权越大（越接近1）。<br>在现实中，我们将$y_t$看作是最近$1/(1-\gamma)$个时间步的$x_t$的加权平均，当$\gamma = 0.95$时，是最近20个时间步的$x_t$值的加权平均。当$\gamma=0.9$时,可以看做是最近10个时间步加权平均。</p><h3 id="动量法"><a href="#动量法" class="headerlink" title="动量法"></a>动量法</h3><script type="math/tex; mode=display">\begin{split}\begin{aligned}\boldsymbol{v}_t &= \gamma \boldsymbol{v}_{t-1} + \eta_t \boldsymbol{g}_t, \\\boldsymbol{x}_t &= \boldsymbol{x}_{t-1} - \boldsymbol{v}_t,\end{aligned}\end{split}</script><p>其中$g_t = \nabla f_i(x)$上式可以看出，如果$\gamma=0$，则上式就是一个普通的随机梯度下降法。$0 \leq \gamma &lt; 1$. $\gamma$一般取0.9。<br>一般，初始化$v_0=0$, 则  </p><script type="math/tex; mode=display">v_1=\eta_t g_t \\ v_2=\gamma v_1+\eta_t g_t = \eta_t g_t(\gamma+1) \\ v_3 = \eta_t g_t (\gamma^2+\gamma+1) \\ v_{inf} = \frac{(\eta_t g_t)\cdot(1-\gamma^{inf+1})}{1-\gamma}\approx \frac{(\eta_t g_t)}{1-\gamma}</script><p>相比原始梯度下降算法，动量梯度下降算法有助于加速收敛。当梯度与动量方向一致时，动量项会增加，而相反时，动量项减少，因此动量梯度下降算法可以减少训练的震荡过程。</p><p>换种方式理解动量法：<br><img src="/2019/02/28/Optimizer/m.jpg" alt="你想输入的替代文字"><br>如上图所示，A点为起始点，首先计算A点的梯度$\nabla a$，下降到B点，  </p><script type="math/tex; mode=display">\theta_{new} = \theta-\eta\nabla a</script><p>其中$\theta$为参数， $\eta$为学习率<br>到达B点后要加上A点的梯度，但是A点的梯度有个衰减值$\gamma$,推荐取0.9，相当于加上一个来自A点递减的加速度。这样的做法可以让早期的梯度对当前梯度的影响越来越小，如果没有衰减值，模型往往会震荡难以收敛，甚至发散。所以B点的参数更新公式是这样的：  </p><script type="math/tex; mode=display">v_t = \gamma v_{t-1}+\eta \nabla b</script><script type="math/tex; mode=display">\theta_{new} = \theta-v_t</script><p>其中$v_{t-1}$表示之前所有步骤累计的动量和，$\nabla b$为B点的梯度方向。这样一步一步下去，带着初速度的小球就会极速的奔向谷底。</p><h2 id="AdaGrad"><a href="#AdaGrad" class="headerlink" title="AdaGrad"></a>AdaGrad</h2><p>假设目标函数有两个参数分别为$x_1$,$x_2$,若梯度下降迭代过程中，始终使用相同的学习率$\eta$:  </p><script type="math/tex; mode=display">x_{1_{new}} = x_1-\eta \frac{\partial f}{\partial x_1}</script><script type="math/tex; mode=display">x_{2_{new}} = x_2-\eta \frac{\partial f}{\partial x_2}</script><p>AdaGard算法根据自变量在每个维度的梯度值来调整各个维度上的学习率，避免学习率难以适应维度的问题。adagrad方法是将每一个参数的每一次迭代的梯度取平方累加再开方，用基础学习率除以这个数，来做学习率的动态更新。<br>$\nabla_{\theta_i} J(\theta)$表示第$i$个参数的梯度，其中$\theta=(\theta_1,\theta_2,…)$有$n$个参数。如果使用SGD来优化第$i$个参数，我们可以表示为:  </p><script type="math/tex; mode=display">\theta_{i\_new} = \theta_i-\eta \nabla_{\theta_i}J(\theta)</script><p>如果使用Adagrad，则可以表示为这样:  </p><script type="math/tex; mode=display">\theta_{i,t+1}=\theta_{i,t}-\frac{\eta}{\sqrt{G_{i,t}+\epsilon}} \nabla_{\theta_{i,t}}J(\theta)</script><p>$i,t$ 表示优化参数$\theta_i$时的第$t$次迭代，$\epsilon$防止分母为0，可以取$10^{-6}$,$G_{i,t}$表示对参数$\theta_i$优化的前$t$步的梯度的累加：  </p><script type="math/tex; mode=display">G_{i,t} = G_{i,t-1}+\nabla_{\theta_{i,t}}J(\theta)</script><p>新公式可以简化成:  </p><script type="math/tex; mode=display">\theta_{t+1}= \theta_t-\frac{\eta}{\sqrt{G_t+\epsilon}}\nabla_{\theta_t}J(\theta)</script><p>可以从上式看出，随着迭代的推移，新的学习率$\frac{\eta}{\sqrt{G_t+\epsilon}}$在缩小，说明Adagrad一开始激励收敛，到了训练的后期惩罚收敛，收敛速度变慢</p><h2 id="RMSprop"><a href="#RMSprop" class="headerlink" title="RMSprop"></a>RMSprop</h2><p>主要解决Adagrad学习率过快衰减问题，类似动量的思想，引入一个超参数，在积累梯度平方项进行衰减.  </p><script type="math/tex; mode=display">s = \gamma \cdot s +(1-\gamma) \cdot \nabla J(\theta) \odot \nabla J(\theta)</script><p>参数$\theta$的迭代目标函数可以改写为:  </p><script type="math/tex; mode=display">\theta_{new} = \theta - \frac{\eta}{\sqrt{s+\varepsilon}} \odot \nabla J(\theta)</script><p>可以看出$s$是梯度的平方的指数加权移动平均值，$\gamma$一般取0.9，有助于解决 Adagrad中学习率下降过快的情况。</p><h2 id="Adaptive-moment-estimation-Adam"><a href="#Adaptive-moment-estimation-Adam" class="headerlink" title="Adaptive moment estimation(Adam)"></a>Adaptive moment estimation(Adam)</h2><p>Adam可以说是用的最多的优化算法，Adam通过计算一阶矩估计和二阶矩估计为不同的参数设计独立的自适应学习率。</p><h2 id="Adabound"><a href="#Adabound" class="headerlink" title="Adabound"></a>Adabound</h2><p>正在学习中</p><p>参考文献：<br><a href="https://zhuanlan.zhihu.com/p/32626442" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/32626442</a><br><a href="https://zhuanlan.zhihu.com/p/31630368" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/31630368</a><br><a href="https://zh.gluon.ai/" target="_blank" rel="noopener">https://zh.gluon.ai/</a><br><a href="https://blog.csdn.net/tsyccnh/article/details/76270707" target="_blank" rel="noopener">https://blog.csdn.net/tsyccnh/article/details/76270707</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近想好好学一学Deep Learning中的优化算法（不能一直Adam了），看了一些文献，用这篇文章做个总结笔记。&lt;/p&gt;
&lt;h2 id=&quot;Gradient-Desent-梯度下降&quot;&gt;&lt;a href=&quot;#Gradient-Desent-梯度下降&quot; class=&quot;heade
      
    
    </summary>
    
      <category term="Deep Learning" scheme="http://yoursite.com/categories/Deep-Learning/"/>
    
    
      <category term="Optimizer" scheme="http://yoursite.com/tags/Optimizer/"/>
    
  </entry>
  
  <entry>
    <title>《Self-Paced Network Embedding》阅读笔记[转+改]</title>
    <link href="http://yoursite.com/2019/02/18/SeedNE/"/>
    <id>http://yoursite.com/2019/02/18/SeedNE/</id>
    <published>2019-02-18T07:36:57.000Z</published>
    <updated>2019-02-20T08:28:18.343Z</updated>
    
    <content type="html"><![CDATA[<p>论文地址: <a href="https://www.kdd.org/kdd2018/accepted-papers/view/self-paced-network-embedding" target="_blank" rel="noopener">SeedNE</a></p><p>部分内容转载自<a href="https://zhuanlan.zhihu.com/p/55104326" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/55104326</a></p><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>传统的NE方法例如DeepWalk, Node2vec, Line是通过将正上下文节点在低维空间中靠近锚节点(anchor node)，而负上下文节点在低维空间中远离锚节点来学习Network Representation.也就是说，在低维空间中拉近相似节点，同时推远不相似节点。当采样负上下文节点时，通常采用预定义基于节点流行程度的采样分布，越流行的节点越有可能被采样为负例。<br>在数学上，这类似一个二分类器。用来把两个相似的节点分类成正相关节点对或负相关节点对。但是随机负例采样的方式无法区别出不同节点的信息，而是将所有节点等价采样。所以，DeepWalk，node2vec,LINE采样负节点是根据一个分布，这个分布依赖于节点的度。因此，采样连边多的节点会得到更好的效果，因为连边多的节点包含更多信息。然而这种方法忽略了度少的节点也可能包含有用的信息。所以不能仅仅用连接信息来决定一个节点的信息量。因此，本文的目标是找到真正有用的节点来训练模型。<br>当前的NE方法所使用的的采样方式是静态的，即采样分布不会随着训练过程而变化。所以在训练模型中，一个节点的信息量是个常量。但是，随着训练过程的继续，一些负例节点会远离锚节点，然而有一些却不会。所以我们应该更加注意这些不好区分的节点。因此，最好在不同的训练阶段对不同概率的节点进行采样。另一方面，不能总是关注不好区分的节点。应该从易到难的采样。</p><p>因此，本文的目标是动态地为训练模型抽取信息负面节点。具体来说，本文提出了一种自步节点采样策略(self-paced)。 该策略可以基于当前模型参数发现每个节点的信息量，然后根据其信息量对负节点进行采样。 此外，这种自定进度的策略可以在训练过程中逐渐对困难的负面节点进行采样。 此外，本文将这种自我采样策略扩展到生成对抗性网络框架。 对七个基准网络数据集进行了大量实验，以验证提出的方法的有效性。</p><h1 id="Sample-Selection"><a href="#Sample-Selection" class="headerlink" title="Sample Selection"></a>Sample Selection</h1><p>Curriculum Learning(课程学习)：<a href="https://blog.csdn.net/qq_25011449/article/details/82914803" target="_blank" rel="noopener">解读</a><br>Self-Paced Learning(自步学习)：<a href="https://blog.csdn.net/selous/article/details/78144377" target="_blank" rel="noopener">解读</a></p><h1 id="Self-Paced-Network-Embedding"><a href="#Self-Paced-Network-Embedding" class="headerlink" title="Self-Paced Network Embedding"></a>Self-Paced Network Embedding</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;论文地址: &lt;a href=&quot;https://www.kdd.org/kdd2018/accepted-papers/view/self-paced-network-embedding&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SeedNE&lt;/a&gt;&lt;/
      
    
    </summary>
    
      <category term="Network Embedding" scheme="http://yoursite.com/categories/Network-Embedding/"/>
    
      <category term="paper" scheme="http://yoursite.com/categories/Network-Embedding/paper/"/>
    
    
      <category term="GAN" scheme="http://yoursite.com/tags/GAN/"/>
    
      <category term="Self-Paced" scheme="http://yoursite.com/tags/Self-Paced/"/>
    
  </entry>
  
  <entry>
    <title>《GraphGAN:Graph Representation Learning with Generative Adversarial Nets》阅读笔记</title>
    <link href="http://yoursite.com/2019/01/22/GraphGAN/"/>
    <id>http://yoursite.com/2019/01/22/GraphGAN/</id>
    <published>2019-01-22T08:57:05.000Z</published>
    <updated>2019-01-24T09:19:46.165Z</updated>
    
    <content type="html"><![CDATA[<p>论文地址:<a href="https://arxiv.org/abs/1711.08267" target="_blank" rel="noopener">GraphGAN</a></p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>GAN是CV上非常火的方法，作者将其引入Network Embedding领域。为了达到这个目的，首先，作者将当前的NE model分成了两类，分别是生成模型(generative model)和判别模型(discriminative model)。简单来说，生成模型。<br>所谓生成模型，就是对于每个节点$v_c$，都存在一个潜在的真实连接分布$p_{true}(v|v_c)$, 这个分布反映了由条件生成样本的概率，因此，生成式模型的目的就是求网络中边的极大似然。比较经典的方法有DeepWalk，是通过随机游走来获得center node的上下文，然后最大化上下文节点的似然。Node2vec拓展了DeepWalk,提出了biased随机游走，使得模型在为给定节点生成上下文节点时具有更多的灵活性。<br>所谓判别模型，目的是学习一个分类器来直接预测边是否存在。将两个节点视为输入特征，然后输出预测的两个节点之间有边的概率，即$p(edge|(v_i,v_j))$,常见的方法有SDNE，PPNE。</p><p>于是，本文结合生成对抗网络(GAN),提出了GraphGAN来同一生成和判别器。其中生成器$G(v|v_c)$试图拟合真实的连接概率分布$p_{true}(v|v_c)$,生成最可能和$v_c$有链接的点。判别器$D(v,v_c)$尝试区分强连接节点对和若连接节点对，然后计算$v$和$v_c$存在边的可能性。简单来说，就是把生成器生成的可能与$v_c$有边的节点放入判别器计算两者有边的概率。</p><p>除此之外GAN框架下，然而生成器的连接分布是通过softmax实现的，但是传统的softmax无法适配生成器，原因如下:<br>(1).传统的softmax对网络中的所有节点一视同仁，缺乏对网络结构相似度信息的考虑。<br>(2).计算成本太高。<br>因此，论文中提出了新的生成器实现方法 Graph Softmax。并且证明GS具有归一化（normalization）、网络结构感知（graph structure awareness）和高计算效率（computational efficiency）的性质。相应的，文中也提出了基于随机游走(random walk)的生成器策略。</p><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><p>这里挑特别的来说。$\mathcal{N}(v_c)$表示和$v_c$直接相连的节点集。我们把给定节点$v_c$与任意节点$v \in \mathcal{V}$的真实连接分布表示为$p_{true}(v|v_c)$。这么看$\mathcal{N}(v_c)$可以看做从$p_{true}(v|v_c)$中采样的集合。文章的目的是学习两个模型:<br><strong>Generator</strong> $G(v|v_c;\theta_G)$ 生成器，尝试拟合真实连接分布$p_{true}(v|v_c)$，并且从节点集$\mathcal{V}$中生成最有可能和$v_c$相连的节点。<br><strong>Discriminator</strong> $D(v,v_c;\theta_G)$ 判别器，目的是判断已对接点$(v,v_c)$的连接性。$D(v,v_c;\theta_G)$输出$v$和$v_c$有边的概率。</p><p>生成器$G$尝试完美拟合$p_{true}(v|v_c)$，并且生成和$v_c$真实邻居高度相似的节点来欺骗判别器。相反，判别器尝试发现输入的顶点是真实的节点对或者有生成器生成出的样本。这是一个极大极小游戏，目标函数$V(G,D)$:  </p><script type="math/tex; mode=display">\min_{\theta_G} \max_{\theta_D} V(G,D)=\sum_{c=1}^V (\mathbb{E}_{v \sim p_{true}(\cdot|v_c)}[\log D(v,v_c;\theta_D)]+\mathbb{E}_{v \sim G(\cdot|v_c;\theta_G)}[\log(1-D(v,v_c;\theta_D))])</script><p>上面这个公式是本文最关键的公式，以我的分析就是：在给定$\theta_D$的情况下，对其最小化。先来分析$\max_{\theta_D}V(G,D)$,即给定$\theta_G$,使原式最大。当给定$\theta_G$时，通过改变$\theta_D$,使$\mathbb{E}_{v \sim p_{true}(\cdot|v_c)}[\log D(v,v_c;\theta_D)]$达到最大（是判别器D拟合真实分布），同时使$\mathbb{E}_{v \sim G(\cdot|v_c;\theta_G)}[\log(1-D(v,v_c;\theta_D))]$最大，即尽可能减小选定节点$v_c$与判别器中生成的$v_c$邻居节点与$v_c$连接的可能性。然后在给定$\theta_D$的情况下，通过改变生成器$\theta_G$继续生成节点，使得$\mathbb{E}_{v \sim G(\cdot|v_c;\theta_G)}[\log(1-D(v,v_c;\theta_D))]$尽可能小，即上一步的判别器尽可能把当前生成器生成的节点认为是邻居。 之后再更新判别器,以此类推。这样$G$和$D$各自提高性能，最终$G$生成的分布和真实连接分布无法区分，这样达到最好的效果。整体过程如下图所示:  </p><p><img src="/2019/01/22/GraphGAN/1.png" alt="你想输入的替代文字"></p><h3 id="Discriminator-Optimization"><a href="#Discriminator-Optimization" class="headerlink" title="Discriminator Optimization"></a>Discriminator Optimization</h3><p>对于判别器来说是个简单的sigmoid函数，来计算两个输入节点的表示向量:  </p><script type="math/tex; mode=display">D(v,v_c;\theta_D)=\frac{1}{1+\exp(-d^\top_v d_{v_c})}</script><p>其中，$d_v$,$d_{v_c}$是两个输入节点关于判别器$D$的表示向量，$\theta_D$是所有节点表示向量的结合。注意到上面的公式只涉及$v$和$v_c$, 我们只需要更新$d_v$,$d_{v_c}$，通过梯度下降的方法可以实现：<br><img src="/2019/01/22/GraphGAN/2.png" alt="你想输入的替代文字"></p><h3 id="Generator-Optimization"><a href="#Generator-Optimization" class="headerlink" title="Generator Optimization"></a>Generator Optimization</h3><p>对于生成器来说，目标是最小化判别器将生成的样本判断为负样本的对数似然（概率）。换句话说，生成器会调整自己的连接分布（通过调整生成的所有节点的向量表示$\theta_G$）来提升对生成样本的判别分数。由于$v$的采样时离散的，所以使用policy gradient来计算$V(G,D)$关于$\theta_G$的梯度：<br><img src="/2019/01/22/GraphGAN/3.png" alt="你想输入的替代文字"><br>为了理解上述公式，注意到$\nabla_{\theta_G}V(G,D)$是一个由$\log(1-D(v,v_c;\theta_D))$加权的梯度$\nabla_{\theta_G}\log G(v|v_c;\theta_G)$的求和，直观上说，这意味着有高概率是负样本的节点会将生成器G“拉着”远离自己（因为我们在$\theta_G$上执行梯度下降）。</p><h3 id="Graph-Softmax"><a href="#Graph-Softmax" class="headerlink" title="Graph Softmax"></a>Graph Softmax</h3><p>graph softmax的核心思想是定义一种新的计算连接性概率的方式，满足以下性质:  </p><ul><li>归一化：$\sum_{v \neq v_c;\theta_G}=1$。</li><li>图结构感知：生成器充分利用网络中的结构信息，来估计真实连接分布，如果两个节点在图上越远，那么他们间有边的概率越小。</li><li>高效的计算：和传统的softmax不同，$G(v|v_c;\theta_G)$的计算应只涉及图中的一小部分点。</li></ul><p>因此，本文以图中节点$v_c$为例，以$v_c$为根构建一棵BFS树$T_c$。$\mathcal{N}_c(v)$为节点$v$在$T_c$上的邻居集合（包括他的父节点和所有子节点）。对于一个given vertex $v$和它的一个邻居$v_i \in \mathcal{N}_c(v)$,定义概率为:  </p><script type="math/tex; mode=display">p_c(v_i|v)=\frac{\exp (g_{v_i}^\top g_v)}{\sum_{v_i \in \mathcal{N}_c(v)} \exp(g_{v_j}^\top g_v)}</script><p>这是一个在$\mathcal{N}_c(v)$上的softmax函数。</p><p>为了计算$G(v|v_c;\theta_G)$,注意到在$T_c$上，根节点$v_c$到每个节点$v$都有一条唯一的路径， 把这条路径记为$P_{v_c \to v}=(v_{r_0},v_{r_1},…,v_{r_m})$,其中$v_{r_0}=v_c$, $v_{r_m}=v$,那么在graph softmax中，将$G(v|v_c;\theta_G)$定义为:  </p><script type="math/tex; mode=display">G(v|v_c;\theta_G)\triangleq (\prod^m_{j=1} p_c(v_{r_j}|v_{r_{j-1}})) \cdot p_c(v_{r_{m-1}}|v_{r_m})</script><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>总的来说，这篇paper应该属于较早将GAN结合到NRL上的尝试， 有不少值得学习的地方，但是从实验部分看，Baselines较少以及试验指标选取中可以看出还有很大的提升空间。该算法主要针对无权图，对于加权图来说并不适配。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;论文地址:&lt;a href=&quot;https://arxiv.org/abs/1711.08267&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;GraphGAN&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduct
      
    
    </summary>
    
      <category term="Network Embedding" scheme="http://yoursite.com/categories/Network-Embedding/"/>
    
      <category term="paper" scheme="http://yoursite.com/categories/Network-Embedding/paper/"/>
    
    
      <category term="GAN" scheme="http://yoursite.com/tags/GAN/"/>
    
      <category term="Graph Softmax" scheme="http://yoursite.com/tags/Graph-Softmax/"/>
    
  </entry>
  
  <entry>
    <title>《Enhanced Network Embeddings via Exploiting Edge Labels》阅读笔记</title>
    <link href="http://yoursite.com/2019/01/22/NE-Edge-Labels/"/>
    <id>http://yoursite.com/2019/01/22/NE-Edge-Labels/</id>
    <published>2019-01-22T03:02:29.000Z</published>
    <updated>2019-01-22T06:31:16.548Z</updated>
    
    <content type="html"><![CDATA[<p>论文地址: <a href="https://arxiv.org/abs/1809.05124?context=physics.soc-ph" target="_blank" rel="noopener">Enhanced Network Embeddings via Exploiting Edge Labels</a></p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>这是DeepWalk团队的一篇论文，目的是捕获网络中的边信息。传统的NE方法通常把节点简单关系当做（0,1）二值，然而边中所包含的丰富的语义信息。本文尝试做Network Embedding的同时保留网络结构和节点关系信息。举个例子来说，真实社交网络中，一个用户可能和他的同事，家人有关系，但是已有的NE方法不能同事捕获好友关系（有边连接），以及边的类型。</p><p>具体来说，本分的方法分为无监督部分和监督部分。其中无监督部分预测节点邻域， 监督部分预测边标签。所以本文模型是个<strong>半监督NE模型</strong>。</p><h2 id="Problem-Definition"><a href="#Problem-Definition" class="headerlink" title="Problem Definition"></a>Problem Definition</h2><p>假定Network Graph $G=(V,E)$是无向图。$L=(l_1,l_2,…,l_{|V|})$是边的类型集。一个含有边类型的Graph可以被重新定义为$G=(V,E_L,E_U,Y_L)$,其中$E_L$是由label的边集，$E_U$是没有label的边集，$E_L \cup E_U =E$。$Y_L$表示$E_L$中边的关系类型集合。论文中假定一条边可以有多重关系，所以对于边$E_i$的label集$Y_L(i) \in Y_L$, $Y_L(i)$可能包含很多类型 所以$Y_L(i) \subseteq L$。目的还是一样，学习一个映射函数$\Phi \to \mathbb{R}^{|V| \times d}$, 其中$d \ll |V|$。</p><h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><p>首先定义损失函数:  </p><script type="math/tex; mode=display">\mathcal{L}=(1-\lambda)\mathcal{L}_s+\lambda\mathcal{L}_r</script><p>其中$\mathcal{L}_s$表示预测节点邻域的损失。$\mathcal{L}_r$表示预测边label的损失。$\lambda$是两种损失的权重。</p><h3 id="Structural-Loss"><a href="#Structural-Loss" class="headerlink" title="Structural Loss"></a>Structural Loss</h3><p>第一部分是最小化无监督网络结构损失，对于一个给定的节点$v$, 要最大化这个节点和它邻域可能性。其中，节点的邻域不一定要一定和该节点有边相连。文章先给出了结构损失的目标函数：  </p><script type="math/tex; mode=display">\mathcal{L}_s=-\sum_{u \in C(v)} \log Pr(u|v)</script><p>这个函数其实就是给定$v$,最大化$v$的邻域的极大似然。其中$Pr(u|v)$是一个softmax函数：  </p><script type="math/tex; mode=display">Pr(u|v)=\frac{\exp(\Phi(u) \cdot \Phi'(v))}{\sum_{u' \in V} \exp(\Phi(u') \cdot \Phi'(v))}</script><p>这其实和DeepWalk一样，一个节点$v$有两个表示向量，$\Phi(v)$和$\Phi’(v)$分别表示该节点作为中心节点和上下文节点的表示。由于计算复杂度较高，所以采用负采样的策略。<br>剩下的问题就是如何构建节点$v$的邻域$C(v)$。一种直接的方式就是从邻接矩阵中选取他的邻居。然后由于现实网络的稀疏性，一个节点只有很少的邻居。为了缓解网络稀疏性的问题， 本文采取了类似于DeepWalk的randomwalk策略。 最终可以得到节点$v$的邻域：  </p><script type="math/tex; mode=display">C(v)=\{v_{i-w},...,v_{i-1}\} \cup \{v_{i+1},...,v_{i+w}\}</script><h3 id="Relational-Loss"><a href="#Relational-Loss" class="headerlink" title="Relational Loss"></a>Relational Loss</h3><p>由于label是为了预测边的，所以需要把每条边表示出来，所以对于边$e=(u,v) \in E$,可以用一下方法来表示这条边:  </p><script type="math/tex; mode=display">\Phi(e)=g(\Phi(u),\Phi(v))</script><p>其中，$g$是一个映射函数用来把两个节点的表示向量转化为他们之间边的表示向量，本文使用了简单的连接操作，即把两个向量直接拼接：  </p><script type="math/tex; mode=display">\Phi(e)=\Phi(u) \oplus \Phi(v)</script><p>这样我们就获得了edge embedding。直接将它输入前馈神经网络，前馈神经网络第$k$层的定义为:  </p><script type="math/tex; mode=display">h^{(k)}=f(W^{(k)}h^{(k-1)}+b^{(k)})</script><p>其中 $h^{(0)}=\Phi(e)$，$f$是除最后一层外采用relu激活函数，最后一层采用sigmoid函数激活,最后一层输出为$\hat{y_i}$。最后最小化二元交叉熵损失函数：</p><script type="math/tex; mode=display">\mathcal{L}_r=\sum^{|L|}_{i=1} H(y_i,\hat{y_i}) + (1-y_i) \cdot \log (1-\hat{y_i})</script><h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>这篇论文从原理到方法实现都非常简单，稍后我也将尝试复现这篇论文，边的标签信息是以前NE方法所没有考虑到的，但这篇论问的局限性是没有考虑边的方向以及权重，这是可以拓展的方向。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;论文地址: &lt;a href=&quot;https://arxiv.org/abs/1809.05124?context=physics.soc-ph&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Enhanced Network Embeddings via Ex
      
    
    </summary>
    
      <category term="Network Embedding" scheme="http://yoursite.com/categories/Network-Embedding/"/>
    
      <category term="paper" scheme="http://yoursite.com/categories/Network-Embedding/paper/"/>
    
    
      <category term="Hawkes process" scheme="http://yoursite.com/tags/Hawkes-process/"/>
    
      <category term="attention" scheme="http://yoursite.com/tags/attention/"/>
    
  </entry>
  
  <entry>
    <title>SDNE:《Structral Deep Network Embedding》阅读笔记</title>
    <link href="http://yoursite.com/2019/01/21/SDNE/"/>
    <id>http://yoursite.com/2019/01/21/SDNE/</id>
    <published>2019-01-21T07:34:36.000Z</published>
    <updated>2019-01-22T02:56:11.352Z</updated>
    
    <content type="html"><![CDATA[<p>论文地址：<a href="https://www.kdd.org/kdd2016/papers/files/rfp0191-wangAemb.pdf" target="_blank" rel="noopener">SDNE</a></p><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>这是一篇比较早的Network Embedding论文， 较早将深度模型应用到NE任务。 首先，本文提出了当前网络表示学习中遇到的三个问题：<br><strong>（1）. 高度非线性</strong><br><strong>（2）. 尽可能保持网络结构</strong><br><strong>（3）. 现实网络的高度稀疏性</strong><br>SDNE的主要目标就是保持网络结构的一阶相似性和二阶相似性。<br>一阶相似性就是网络中边相连的节点对之间具有的相似性。<br>二阶相似性就是在一个Graph中，拥有共同邻居但是不直接向相连的两个节点具有的相似性。</p><p>其中，一阶相似性主要反映了网络的局部特征。 二阶相似性反映了网络的全局特征。</p><h3 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h3><p>本文的模型主要如下图所示：</p><p><img src="/2019/01/21/SDNE/SDNE.png" alt="你想输入的替代文字"></p><p>这张图看上去有点复杂，实则原理非常简单。</p><p>模型分为无监督部分和有监督部分，无监督部分是一个<strong>深度自编码器</strong> 用来捕获二阶相似度（保留全局结构），监督部分是一个拉普拉斯特征映射捕获一阶相似度（局部结构）。呃呃呃，Emmmmm ,不知道是我理解有问题还是其他原因，文章里说的和我理解的不太一样 /(ㄒoㄒ)/~~。 然后介绍一下具体的模型结构：  </p><p>深度自编码器的编码部分：  </p><script type="math/tex; mode=display">y_i^{(k)}=\sigma{(W^{(k)}y_i^{(k-1)}+b^{(k)})}, k=2,...,K</script><p>假设第$k$层是 节点$v$的表示向量（仅考虑全局信息），那么从第$k$层开始解码，最终得到$\hat{x_i}$, 所以自编码器的误差就是输入节点$v$的邻接向量的重构误差。所以，二阶相似度损失函数定义为:  </p><script type="math/tex; mode=display">\mathcal{L}=\sum_{i=1}^n{||\hat{x_i}-x_i||^2_2}</script><p>值得注意的是，由于网络的稀疏性，邻接矩阵中的0元素远多于非0元素，使用邻接矩阵作为输入的话要处理很多0，这样就做了太多无用功了。为了解决这个问题，对损失函数做了改进如下：  </p><script type="math/tex; mode=display">\mathcal{L_{2nd}}=\sum_{i=1}^n||(\hat{x_i}-x_i)\odot{b_i}||^2_2=||\hat{X}-X\odot{B}||^2_F</script><p>其中$\odot$是哈马达乘积，表示对应元素相乘。$b_i=\{b_{i,j}\}^n_{j=1}$， 邻接矩阵中的0对应$b=1$, 非0元素的$b&gt;1$,这样的目的是对于有边连接的节点增加惩罚。可以理解为对有边连接的节点赋予更高权重。</p><p>以上我们获得了二阶相似度的损失函数。在介绍一阶相似度之前，我们先来看看<strong>拉普拉斯映射（Laplacian Eigenmap）</strong>  其实LE也是一种经典的NRL方法，主要目的也是降维。其目标函数如下所示:  </p><script type="math/tex; mode=display">\sum_{i,j} W_{ij}||y_i-y_j||^2</script><p>LE是通过构建相似关系图来重构局部特征结构,如果放在网络结构中来说,如果节点$v_i$和$v_j$很接近（有边），那么他们在embedding space中的距离也应该相应接近。$y_i$和$y_j$就表示他们在特征空间中的表示。因此，本文定义了保持一阶相似度的目标函数：  </p><script type="math/tex; mode=display">\mathcal{L_{1st}}=\sum_{i,j=1}^n{s_{i,j}||y_i^{(K)}-y_j^{(K)}||^2_2}=\sum_{i.j=1}^n{s_{i,j}||y_i-y_j||^2_2}</script><p>具体来说，$K$就是自编码器第$K$层的输出，即编码结果，需要保持一条边的两个节点在嵌入空间中的表示相对接近。</p><p>最终 结合一阶相似度和二阶相似度，本文给出了SDNE的目标函数：  </p><script type="math/tex; mode=display">\mathcal{L_{mix}}=\mathcal{L_{2nd}+\alpha{\mathcal{L_{1st}}}}+\nu{\mathcal{L_{reg}}} =||(\hat{X}-X)\odot{B}||^2_F+\alpha{\sum_{i.j=1}^n{s_{i,j}||y_i-y_j||^2_2}}+\nu{\mathcal{L_{reg}}}</script><p>其中，为了防止过拟合，添加了$\mathcal L2$-norm单元$\mathcal{L_{reg}}$来防止过拟合:  </p><script type="math/tex; mode=display">\mathcal{L_{reg}}=\frac{1}{2}\sum_{k=1}^k({||W^{(k)}||^2_F+||\hat{W}^{k}||_F^2})</script><h3 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h3><p>使用SGD来优化$\mathcal{L_{mix}}$。具体算法如下：<br><img src="/2019/01/21/SDNE/al.png" alt="你想输入的替代文字"></p><h3 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h3><p>不得不感叹这篇论文的实验是真的充分，分别在Link Prediction，Vertex Classification，Visualization上做了评价，并且都取得了高于Baselines的效果。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;论文地址：&lt;a href=&quot;https://www.kdd.org/kdd2016/papers/files/rfp0191-wangAemb.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDNE&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;Introduc
      
    
    </summary>
    
      <category term="Network Embedding" scheme="http://yoursite.com/categories/Network-Embedding/"/>
    
      <category term="paper" scheme="http://yoursite.com/categories/Network-Embedding/paper/"/>
    
    
      <category term="Deep Learning" scheme="http://yoursite.com/tags/Deep-Learning/"/>
    
      <category term="semi-supervised model" scheme="http://yoursite.com/tags/semi-supervised-model/"/>
    
  </entry>
  
  <entry>
    <title>图片边缘检测并且拟合直线</title>
    <link href="http://yoursite.com/2019/01/19/edge-detection-pj/"/>
    <id>http://yoursite.com/2019/01/19/edge-detection-pj/</id>
    <published>2019-01-18T16:00:00.000Z</published>
    <updated>2019-01-19T04:11:50.156Z</updated>
    
    <content type="html"><![CDATA[<p>前段时间做了一个简单的小项目，需求是测量图片中布的褶皱角度，第一次做CV的东西，决定用这个blog记录一下。 项目源码在:<a href="https://github.com/zhuo931077127/edge-detection" title="edge-detection" target="_blank" rel="noopener">edge-detection</a></p><p>先看看传统的边缘检测方法的效果:</p><p><img src="/2019/01/19/edge-detection-pj/tra.png" alt="你想输入的替代文字"></p><p>第一张图是原始图，由于本项目要求竟要求图片上半部分的褶皱角度，所以仅考虑上半部分的背景干扰，可以看出高斯，梯度，非极大抑制这三种方法都无法有效的排除干扰。<br>然后我们用canny算法试试。<br>步骤是先把图片转化为灰度图，然后用canny算子做边缘检测。<br>代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">gray = cv.cvtColor(image, cv.COLOR_RGB2GRAY)</span><br><span class="line">edges = cv.Canny(gray, 50, 310)  # apertureSize参数默认其实就是3  # 50 310</span><br><span class="line"># cv.imshow(&quot;edges&quot;, edges)</span><br><span class="line">edge = Image.fromarray(edges)</span><br><span class="line">edge.save(&quot;edge.jpeg&quot;)</span><br></pre></td></tr></table></figure></p><p>结果如下:  </p><p><img src="/2019/01/19/edge-detection-pj/edge.jpeg" alt="你想输入的替代文字"></p><p>霍夫线性变换拟合直线:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">lines = cv.HoughLines(edges, 1, np.pi / 180, 68)  # 68</span><br><span class="line">   # l1 = lines[:, 0, :]</span><br><span class="line">   # print(l1)</span><br><span class="line">   mink = float(&apos;inf&apos;)</span><br><span class="line">   maxk = -float(&apos;inf&apos;)</span><br><span class="line">   for line in lines:</span><br><span class="line">       rho, theta = line[0]  # line[0]存储的是点到直线的极径和极角，其中极角是弧度表示的。</span><br><span class="line">       a = np.cos(theta)  # theta是弧度</span><br><span class="line">       b = np.sin(theta)</span><br><span class="line">       x0 = a * rho  # 代表x = r * cos（theta）</span><br><span class="line">       y0 = b * rho  # 代表y = r * sin（theta）</span><br><span class="line">       x1 = int(x0 + 1000 * (-b))  # 计算直线起点横坐标</span><br><span class="line">       y1 = int(y0 + 1000 * a)  # 计算起始起点纵坐标</span><br><span class="line">       x2 = int(x0 - 1000 * (-b))  # 计算直线终点横坐标</span><br><span class="line">       y2 = int(y0 - 1000 * a)  # 计算直线终点纵坐标    注：这里的数值1000给出了画出的线段长度范围大小，数值越小，画出的线段越短，数值越大，画出的线段越长</span><br><span class="line">       print(&quot;x1: %s, y1:%s, x2:%s, y2:%s&quot; % (x1, y1, x2, y2))</span><br><span class="line">       k = (y2 - y1) / (x2 - x1)</span><br><span class="line">       if k &gt; maxk:</span><br><span class="line">           maxk = k</span><br><span class="line">           xmax1 = x1</span><br><span class="line">           ymax1 = y1</span><br><span class="line">           xmax2 = x2</span><br><span class="line">           ymax2 = y2</span><br><span class="line">           lineMax = line</span><br><span class="line">       if k &lt; mink:</span><br><span class="line">           mink = k</span><br><span class="line">           xmin1 = x1</span><br><span class="line">           ymin1 = y1</span><br><span class="line">           xmin2 = x2</span><br><span class="line">           ymin2 = y2</span><br><span class="line">           lineMin = line</span><br><span class="line">   cv.line(image, (xmax1, ymax1), (xmax2, ymax2), (255, 0, 0), 2)  # 点的坐标必须是元组，不能是列表。</span><br><span class="line">   cv.line(image, (xmin1, ymin1), (xmin2, ymin2), (255, 0, 0), 2)  # 点的坐标必须是元组，不能是列表。</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>值得注意的是，拟合直线过程中HoughLines会发现很多直线，因此，我选择了斜率最大和最小的两条直线做为最终的直线。画在图上的话就是酱紫的结果:</p><p><img src="/2019/01/19/edge-detection-pj/line.png" alt="你想输入的替代文字"></p><p>所以：总的过程可以概括如下:</p><p><img src="/2019/01/19/edge-detection-pj/final.jpeg" alt="你想输入的替代文字"></p><p>现在想这么弱智的项目居然还花了几天时间做，我是真滴蠢哦（T-T）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;前段时间做了一个简单的小项目，需求是测量图片中布的褶皱角度，第一次做CV的东西，决定用这个blog记录一下。 项目源码在:&lt;a href=&quot;https://github.com/zhuo931077127/edge-detection&quot; title=&quot;edge-detect
      
    
    </summary>
    
      <category term="project" scheme="http://yoursite.com/categories/project/"/>
    
      <category term="Computer Vision" scheme="http://yoursite.com/categories/project/Computer-Vision/"/>
    
    
      <category term="Edge detection" scheme="http://yoursite.com/tags/Edge-detection/"/>
    
  </entry>
  
  <entry>
    <title>HTNE:《Embedding Temporal Network via Neighborhood Formation》阅读笔记</title>
    <link href="http://yoursite.com/2019/01/17/HTNE/"/>
    <id>http://yoursite.com/2019/01/17/HTNE/</id>
    <published>2019-01-16T16:00:00.000Z</published>
    <updated>2019-01-19T13:37:37.503Z</updated>
    
    <content type="html"><![CDATA[<p>论文地址：<a href="https://dl.acm.org/citation.cfm?id=3220054" target="_blank" rel="noopener">HTNE</a></p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>本文出发点在于捕获动态网络中节点和边的变化来在embedding中保持网络结构，举个简单的例子来说，如Fig. 1所示，是一个共同作者网络图。数字标注的节点是author，方框内是co-authored paper. 可以看到图中每个节点每条边加入网络中的时间是不同的。根据图中的信息，可以分析出例如前期1和2，3合作较紧密，后期转为了6,7。 并且(b)中所示，同一条边可能多次出现，这就比传统的单条边拥有更多语义信息。</p><p><img src="/2019/01/17/HTNE/Fig1.png" alt="你想输入的替代文字"></p><p>另外，最近也有方法对动态网络的embedding做了研究，比如[29][30]的方法。但是他们的目的是将时间线分段为固定时间窗来对动态建模，但是这些方法依然没有考虑动态过程也就是网络随时序动态变化的信息。</p><p>因此，本文提出了基于霍克斯过程（Hawkes process）的时序网络表示学习方法，该方法是由序列事件驱动的（也就是序列的变化） 如Fig .1(b)所示 (b)图为节点1的邻域生成序列。霍克斯过程的思路是说历史上发生的事情对未来的概率密度函数有影响，只是随着时间流逝这种影响会逐渐减弱（Decay）。本文提出用霍克斯过程来捕获时间序列（也就是邻域生成序列）的激励效应。 尤其是历史事件对当前事件的影响。</p><p>通过把成对的向量映射到基本速率和历史影响，从而把低维向量被输入Hawkes过程。 </p><p>另外历史邻居当前邻居的影响，不同节点是不同的，所以本文使用attention model来学习历史邻居对当前邻居影响的量化表示。</p><p>值得注意的是，本文目标是优化邻域生成序列的极大似然估计即<strong>条件强度函数</strong>（conditional intensity function）来邻域生成序列的到达率，而不是条件概率函数</p><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><h3 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h3><p>本文通过跟踪节点邻域的形成来捕获网络的形成过程。<br><strong>Definition 1</strong> : 时序网络 $G=(V,E,A)$, $A$ 是事件集， 边$(x,y) \in E$ 被表示为按时间顺序的时间序列，例如， $\mathbf{a}_{x,y}=\{a_1\to{a_2}\to{…}\}\subset\mathcal{A}$, $a_i$ 表示时间$t_i$时刻的一个事件。  </p><p>因此，网络中节点的相邻邻居可以根据与邻居的交互事件的时序被组织为序列，表示邻域形成过程。</p><p><strong>Definition 2</strong> : 对于给定节点$x$,邻域表示为$N(x)=\{y_i|i=1,2…\}$.$x$的目标邻居到达事件可以表示为$\{x:(y_1,t_1)\to(y_2,t_2)\to…\to(y_n,t_n)\}$,即邻域形成序列。每个元组表示在时间戳$t_i$时，$x$与$y_i$建立边。</p><h3 id="Hawkes-Process"><a href="#Hawkes-Process" class="headerlink" title="Hawkes Process"></a>Hawkes Process</h3><p>点过程（Point Process）通过假设t时刻前的历史事件可以影响当前事件的发生，来对离散序列事件建模。<br>对于一个给定的节点$x \in V$, 在$x$的邻域生成序列中，到达目标邻居$y$的条件强度函数（或者可以说是$x$与$y$有边的可能性强度）可以表示为：  </p><script type="math/tex; mode=display">\tilde{\lambda}_{y|x}(t)=\mu_{x,y}+\sum_{t_h<t}{\alpha_{h,y}\kappa(t-t_{h})}</script><p>其中，$\mu_{x,y}$表示构建一条连接节点$x$和$y$的基本率(base rate)，$h$是t时刻前的历史目标节点，$\alpha_{h,y}$表示一个$t_h$时刻的历史目标节点$h$（该节点是$x$的邻居）对当前邻居$y$的影响强度。$\sum_{t_h&lt;t}$表示遍历t时刻前$x$的所有邻居。$\kappa(t-t_{h})$表示随时间的衰减，可以表示成指数函数：  </p><script type="math/tex; mode=display">\kappa(t-t_h)=\exp(-\delta_s(t-t_h))</script><p>其中，减少率 $\delta$是一个源依赖参数，对于每一个源节点（每个序列的根），历史邻居对当前邻居形成的影响强度是不同的。具体来说，如果$\kappa$越大，说明$t_h$时刻的邻居对当前邻居的影响越大，即 $-\delta_s(t-t_h)$越大, $\delta_s(t-t_h)$越小，因为$t$是当前时刻的邻居，所以当$t_h$越接近当前邻居时刻时，$\kappa$越大，这就说明了里当前时刻之前越近的邻居，对当前时刻邻居的影响越大。<br>综上所述，$\kappa$的具体意义是随时间衰减的影响，其中$\delta_s$参数表示对于不同的源节点，影响是不同的。</p><p>如果$\tilde{\lambda}_{y|x}(t)$ 越大，说明x和y有边的可能性也越大。</p><p>直观的来看，基本率（base rate）$\mu_{x,y}$揭示了节点x和节点y之间的连接可能性。为了简洁，本文使用了<strong>负平方欧式距离（negative squared Euclidean）</strong>来反映表示向量间的相似度: $\mu_{x,y}=f(\mathbf{e}_x,\mathbf{e}_y)=-||\mathbf{e}_x-\mathbf{e}_y||^2$。同样的，在计算历史邻居$h$对当前邻居$y$的影响时，也采用这个方法，即： $\alpha_{h,y}=f(\mathbf{e}_h,\mathbf{e}_y)=-||\mathbf{e}_h-\mathbf{e}_y||^2$。<br>因为条件强度函数必须为正，所以使用如下公式: $\lambda_{y|x}(t)=\exp(\tilde\lambda_{y|x}(t))$。$exp()$对原函数进行了归一化，所以问题就转化为了given $x$, maximize likelihood: $p(y|x)$. 这就与传统的NE方法差不多了。。。</p><h3 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h3><p>根据论文中（3）式，可以看出，$\sum_{t_h&lt;t}{\alpha_{h,y}\kappa(t-t_{h})}$这一部分主要描述了历史邻居对当前邻居的影响，但是完全忽略了源节点$x$，因为源节点$x$的变化也会影响到历史邻居对当前邻居的亲近程度(affinity)。因此，本文引入了<strong>attention model</strong>。as follows：  </p><script type="math/tex; mode=display">w_{h,x} = \frac{\exp(-||\mathbf{e}_x-\mathbf{e}_h||^2)}{\sum_{h'}{\exp(-||\mathbf{e}_x-\mathbf{e}_{h'}||^2)}}</script><p>这是一个softmax函数 来根据源节点$x$的不同为它的邻居赋予不同权重。</p><p>最后， 历史邻居与当前邻居的连接紧密程度可以表示为:</p><script type="math/tex; mode=display">\alpha_{h,y}=w_{h,x}f(\mathbf{e}_h,\mathbf{e}_y)</script><h3 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h3><p>目标函数即为给定节点$x$以及基于邻域形成序列的霍克斯过程, 生成节点$y$的条件概率。 公式如下：</p><script type="math/tex; mode=display">p(y|x, \mathcal{H}_x(t)) = \frac{\lambda_{y|x}(t)}{\sum_{y'}{\lambda_{y'|x}(t)}}</script><p>目标函数即为所有节点对的极大似然：</p><script type="math/tex; mode=display">\log \mathcal{L}=\sum_{x\in{\mathcal{V}}}{\sum_{y\in{\mathcal{H}_x}}}{\log{p(y|x,\mathcal{H}(t))}}</script><p>最后，由于softmax过程是calculating expensive，所以采用负采样优化损失函数。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;论文地址：&lt;a href=&quot;https://dl.acm.org/citation.cfm?id=3220054&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;HTNE&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Int
      
    
    </summary>
    
      <category term="Network Embedding" scheme="http://yoursite.com/categories/Network-Embedding/"/>
    
      <category term="paper" scheme="http://yoursite.com/categories/Network-Embedding/paper/"/>
    
    
      <category term="Hawkes process" scheme="http://yoursite.com/tags/Hawkes-process/"/>
    
      <category term="attention" scheme="http://yoursite.com/tags/attention/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://yoursite.com/2019/01/16/hello-world/"/>
    <id>http://yoursite.com/2019/01/16/hello-world/</id>
    <published>2019-01-15T16:00:00.000Z</published>
    <updated>2019-01-17T06:48:31.411Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
      <category term="test" scheme="http://yoursite.com/categories/test/"/>
    
    
  </entry>
  
</feed>
